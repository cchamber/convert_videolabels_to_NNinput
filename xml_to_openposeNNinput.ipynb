{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "\n",
    "def merge_dicts(a,b):\n",
    "    de = defaultdict(list, a)\n",
    "    for i, j in b.items():\n",
    "        de[i].extend(j)\n",
    "    return de\n",
    "\n",
    "def polygon_xml(ob):\n",
    "    tlist = []\n",
    "    ylist = []\n",
    "    xlist = []\n",
    "    for itrial in ob.iter('polygon'):# go thru polygons\n",
    "        for ifield in itrial: \n",
    "            if ifield.tag == 't':\n",
    "                t = int(ifield.text)\n",
    "            if ifield.tag == 'pt':\n",
    "                for ipt in ifield:\n",
    "                    if ipt.tag == 'x':\n",
    "                        xlist.append(int(ipt.text)) \n",
    "                    elif ipt.tag == 'y':\n",
    "                        ylist.append(int(ipt.text))\n",
    "                        tlist.append(t)\n",
    "    return tlist, xlist, ylist\n",
    "\n",
    "def video_xml(fpath,user):\n",
    "    tree = ET.parse(fpath)\n",
    "    root = tree.getroot()\n",
    "    zpartlist = []; ztlist = []; zxlist = []; zylist = [];\n",
    "    for ob in root.iter('object'): # goes through body parts\n",
    "        for iname in ob.iter('name'):\n",
    "            dum=1\n",
    "        tlist,xlist,ylist = polygon_xml(ob)\n",
    "        partlist = [iname.text]*len(tlist)\n",
    "        zpartlist.extend(partlist)\n",
    "        ztlist.extend(tlist)\n",
    "        zxlist.extend(xlist)\n",
    "        zylist.extend(ylist)\n",
    "    flist = [int(os.path.basename(fpath)[1:-4])]*len(zylist)\n",
    "    userlist = [user]*len(zylist)\n",
    "#     return flist,zpartlist,zxlist,zylist,ztlist\n",
    "    return {'user':userlist,'video':flist,'part': zpartlist, 'x': zxlist, 'y': zylist, 't': ztlist}\n",
    "\n",
    "def box_coco(df):\n",
    "    df = df.reset_index()\n",
    "    boxlist = np.asarray([np.min(df.x), np.min(df.y), np.max(df.x)-np.min(df.x), np.max(df.y)-np.min(df.y)]) # l,b,w,h\n",
    "    xy = np.asarray([val for pair in zip(df.x, df.y) for val in pair])\n",
    "    df_out = df.loc[0,:]\n",
    "    df_out['box'] = boxlist\n",
    "    df_out['box_seg'] = xy\n",
    "    df_out = df_out[['part','x', 'y', 'box','box_seg']]\n",
    "    return df_out\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def build_list(row_idx,xs):\n",
    "    nparts = 17\n",
    "    x_list =[0]*nparts\n",
    "    for i, irow in enumerate(row_idx):\n",
    "        x_list[int(irow)] = xs[i]\n",
    "    return x_list\n",
    "\n",
    "def get_anno(df):\n",
    "    nparts = 17\n",
    "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "    print(np.unique(df.video))\n",
    "    print(np.unique(df.id))\n",
    "    print(df.loc[df.partlabel=='bbox',:].reset_index())\n",
    "    box_coord = list(map(int,df.loc[df.partlabel=='bbox',:].reset_index().box[0]))\n",
    "    dfparts = df.loc[df.partlabel!='bbox',:].sort_values('partnumber').reset_index()\n",
    "    row_idx = dfparts.partnumber.dropna().tolist()\n",
    "    xs = dfparts.x[~dfparts.partnumber.isnull()].tolist(); ys = dfparts.y[~dfparts.partnumber.isnull()].tolist()\n",
    "    vs = [2]*len(xs)\n",
    "    x_list = list(map(int,build_list(row_idx,xs))); y_list = list(map(int,build_list(row_idx,ys))); v_list = list(map(int,build_list(row_idx,vs)))\n",
    "    partvec = list(itertools.chain(*zip(x_list, y_list, v_list)))\n",
    "    num_keypoints = len(row_idx)\n",
    "    \n",
    "    box = df[df.partlabel=='bbox'].reset_index()\n",
    "    area = int(np.round(np.prod(box.box[0][-2:])))\n",
    "    seg = list(box.box_seg[0].astype(int))\n",
    "    id = box.id[0]\n",
    "    image_id = box.imageid[0]\n",
    "    return {\"bbox\": box_coord, \"keypoints\": partvec, \"num_keypoints\": num_keypoints, \"segmentation\": [seg], \"area\": area,\\\n",
    "           \"category_id\": 1,\"iscrowd\": 0, \"id\":id, \"image_id\":image_id}\n",
    "\n",
    "def rescale_values(df, new_max):\n",
    "    df['max'] = df[[\"ncols\", \"nrows\"]].max(axis=1)\n",
    "    cols = ['x','y', 'ncols', 'nrows','box', 'box_seg'] \n",
    "    df[cols] = df[cols].div(df['max'],axis=0)*new_max\n",
    "    for icol in cols:\n",
    "        if (icol == 'ncols')|(icol == 'nrows'):\n",
    "            df[icol] = df[icol].astype(int)\n",
    "        else:\n",
    "            df[icol] = df[icol].apply(np.around)\n",
    "    return df\n",
    "\n",
    "def get_image(df):\n",
    "    df = df.reset_index().loc[0,:]\n",
    "    return {'file_name':str(df.imageid)+'.jpg', 'id': df.imageid, 'height':int(df.nrows), 'width':int(df.ncols)}\n",
    "\n",
    "def remove_duplicates(df, df_frame, df_end):\n",
    "    print(df.video.unique()[0])\n",
    "    print(df_frame[df_frame.video==df.video.unique()[0]].frame)\n",
    "    print(int(df_frame[df_frame.video==df.video.unique()[0]].frame))\n",
    "    frame = int(df_frame[df_frame.video==df.video.unique()[0]].frame)\n",
    "    if len(df_end[df_end.video==df.video.unique()[0]])>0:\n",
    "        print(df_end)\n",
    "        frame_end = int(df_end[df_end.video==df.video.unique()[0]].frame)\n",
    "        df_out = df[(df.t>=frame)&(df.t<=frame_end)]\n",
    "    else:\n",
    "        df_out = df[df.t>=frame]\n",
    "    return df_out\n",
    "\n",
    "def frame_reduce(df,step):\n",
    "    return df.reset_index().loc[df.reset_index().t % step == 0,:].drop(['video','partlabel','index', 'person'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# notes: \n",
    "\n",
    "# only deals with 1 subject per frame - change get_anno\n",
    "\n",
    "step = 4 # how many frames? 1 in 'step' frames\n",
    "\n",
    "new_max = 640 # images are resized relative to some max npixels. Images in COCO are max 640 pixels\n",
    "\n",
    "npartitions = 2 # how many partitions for train/test division? typical would be 10\n",
    "\n",
    "json_name = '_infant_pose.json' # output file name\n",
    "\n",
    "parts = ['ose', 'l_eye', 'r_eye', 'l_ear', 'r_ear', 'l_shoulder', 'r_shoulder', 'l_elbow', \\\n",
    " 'r_elbow', 'l_wrist', 'r_wrist', 'l_hip', 'r_hip', 'l_kee', 'r_kee', 'l_akle', 'r_akle']\n",
    "\n",
    "categories = [{'id': 1,'keypoints': ['nose','left_eye','right_eye','left_ear','right_ear','left_shoulder',\n",
    "        'right_shoulder','left_elbow','right_elbow','left_wrist','right_wrist','left_hip','right_hip','left_knee',\\\n",
    "        'right_knee','left_ankle','right_ankle'],'name': 'person',\\\n",
    "        'skeleton': [[16, 14],[14, 12],[17, 15],[15, 13],[12, 13],[6, 12],[7, 13],[6, 7],[6, 8],[7, 9],[8, 10],[9, 11],\\\n",
    "        [2, 3],[1, 2],[1, 3],[2, 4],[3, 5],[4, 6],[5, 7]],'supercategory': 'person'}]\n",
    "\n",
    "image_path = './files/image/*'\n",
    "xmlpath = './files/xml/*'\n",
    "jsonpath = './files/labels_NN_input'\n",
    "outputimagepath = './files/image_NN_input'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# find image size for each folder\n",
    "vidlist = []; rowlist = []; collist = []\n",
    "img_folder = sorted(glob.glob(image_path))\n",
    "for fpath in img_folder:\n",
    "    imgfile = sorted(glob.glob(os.path.join(fpath,'*')))[0]\n",
    "    vidlabel = int(os.path.basename(fpath)[1:])\n",
    "    img = cv2.imread(imgfile,0)\n",
    "    nrows = len(img)\n",
    "    ncols = len(img[0])\n",
    "    vidlist.append(vidlabel); rowlist.append(nrows); collist.append(ncols);    \n",
    "df_vid = pd.DataFrame(dict(video = vidlist, nrows = rowlist, ncols = collist))\n",
    "\n",
    "# loop over user folders, get annotations\n",
    "xml_folder = sorted(glob.glob(xmlpath))\n",
    "zdict = {'user':[],'video':[],'part': [], 'x': [], 'y': [], 't': []}\n",
    "for fpaths in xml_folder:\n",
    "    user = os.path.basename(fpaths)\n",
    "    fpaths = sorted(glob.glob(os.path.join(fpaths,'*.xml')))\n",
    "    for fpath in fpaths:\n",
    "        dict_file = video_xml(fpath, user)\n",
    "        zdict = merge_dicts(zdict,dict_file)\n",
    "\n",
    "df = pd.DataFrame(zdict, columns=['user','video', 'part', 'x', 'y', 't'])\n",
    "df['box'] = np.nan; df['box_seg'] = np.nan; df['partnumber'] = np.nan\n",
    "df['person'] = df['part'].str[-1:].astype(int)\n",
    "\n",
    "# leave out videos with 2 infants\n",
    "# find all videos where person=1 is there...remove\n",
    "df['person_type'] = df['part'].str[-3:-2]\n",
    "# remove adult labels, take infants only\n",
    "df_1 = df[df.person_type=='b']\n",
    "\n",
    "# for now, remove videos where there is a person label =1, change get anno to handle many people in frame\n",
    "videos_w_2_infants = df_1[df_1.person==1].video.unique()\n",
    "df = df_1[~np.isin(df_1.video, videos_w_2_infants)]\n",
    "\n",
    "# leave out suffix from string: b_0 from label string\n",
    "df['partlabel'] = df['part'].str[:-4]\n",
    "dfbox = df[df.partlabel=='bbox']\n",
    "dfparts = df[df.partlabel!='bbox']\n",
    "\n",
    "dfparts = dfparts.groupby(['user', 'video','person','partlabel','t']).mean().reset_index()\n",
    "dfbox = dfbox.groupby(['user', 'video','person','partlabel','t']).apply(box_coco).reset_index()\n",
    "df1 = dfbox.append(dfparts)\n",
    "df1 = df1[['user','video','person','part','partlabel','partnumber','t','x','y','box', 'box_seg']]\n",
    "for ii,ipart in enumerate(parts):\n",
    "    df1.loc[df1.partlabel==ipart, 'partnumber'] =int(ii)\n",
    "df2 = pd.merge(df1,df_vid, on='video', how='inner')\n",
    "\n",
    "# rescale all values\n",
    "df2 = rescale_values(df2, new_max)\n",
    "\n",
    "# add imageid and id\n",
    "imageid_list = []; id_list = [];\n",
    "for i in range(len(df2)):\n",
    "    imageid_list.append(int('1%06d%06d' % (df2.loc[i,'video'], df2.loc[i,'t'])))\n",
    "    id_list.append(int('1%06d%06d%02d' % (df2.loc[i,'video'], df2.loc[i,'t'], df2.loc[i,'person'])))\n",
    "df2['imageid'] = imageid_list\n",
    "df2['id'] = id_list\n",
    "\n",
    "# divide into train/test by video\n",
    "ntest = np.ceil(len(df2.video.unique())/npartitions)\n",
    "ntrain = len(df2.video.unique())-ntest\n",
    "train_test_idx = np.concatenate((np.zeros(int(ntrain)), np.ones(int(ntest)))).astype(int)\n",
    "random.shuffle(train_test_idx) \n",
    "df_vid['train_test'] = train_test_idx\n",
    "\n",
    "df3 = df2.groupby(['video','partlabel','person']).apply(lambda x:frame_reduce(x,step)).reset_index()\n",
    "df3 = pd.merge(df3,df_vid[['video', 'train_test']], how='left', on='video')\n",
    "\n",
    "# remove random mislabels here. Check for these when new data is added\n",
    "# df3.loc[(df3.partlabel=='b_elbow'), 'partlabel'] = 'r_elbow'\n",
    "\n",
    "if 1-os.path.isdir(jsonpath):\n",
    "    os.mkdir(jsonpath)\n",
    "\n",
    "# save .json annotation file: train and test files\n",
    "sets = ['train','val']\n",
    "for i,iset in enumerate(sets):\n",
    "    zdf = df3[df3.train_test==i]\n",
    "    image_info = zdf.groupby('imageid').apply(get_image)\n",
    "    anno = zdf.groupby('id').apply(get_anno)\n",
    "    json_dict = {\"annotations\":anno.tolist(), \"categories\":categories, \"images\":image_info.tolist()}\n",
    "    with open(os.path.join(jsonpath,'person_keypoints_'+iset+json_name), 'w') as f:\n",
    "        json.dump(json_dict, f, cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resize images and save to train/test folder\n",
    "\n",
    "outputimagepath = './files/image_NN_input'\n",
    "\n",
    "out_folder = ['train_infant','val_infant']\n",
    "\n",
    "new_max = 640\n",
    "\n",
    "if 1-os.path.isdir(outputimagepath):\n",
    "    os.mkdir(outputimagepath)\n",
    "image_folders = os.listdir(image_path[:-1])\n",
    "\n",
    "for ifolder in out_folder:\n",
    "    new_image_path = os.path.join(outputimagepath,ifolder)\n",
    "    if 1-os.path.isdir(new_image_path):\n",
    "        os.mkdir(new_image_path)\n",
    "\n",
    "image_folders_1 = [os.path.join(image_path[:-1],'_%06d' % (int(i[1:]))) for i in sorted(image_folders)]\n",
    "\n",
    "\n",
    "for i, ifolder in enumerate(image_folders_1):\n",
    "    vidnumber = int(os.path.basename(ifolder)[1:])\n",
    "    ts = df3[df3.video==vidnumber].t.unique()\n",
    "    print(ifolder)\n",
    "    print(vidnumber)\n",
    "    print(ts)\n",
    "    x = [ifolder+'/'+str(it)+'.jpg' for it in ts]\n",
    "    train_test = df_vid[df_vid.video == vidnumber].train_test\n",
    "    df_image = pd.DataFrame()\n",
    "    df_image['images'] = pd.Series(x)\n",
    "    df_image['image_number'] = pd.Series(ts)\n",
    "    image_files = df_image.sort_values('image_number').images.tolist()\n",
    "    \n",
    "    for j, iimage in enumerate(image_files):\n",
    "        I = cv2.imread(iimage)\n",
    "        rows = len(I[0]); cols = len(I); \n",
    "        max_image = np.max([rows,cols])\n",
    "        new_image_name = '1%06d%06d.jpg' % (int(os.path.basename(ifolder)[1:]), int(os.path.basename(iimage)[:-4]))\n",
    "        resized_I = cv2.resize(I, (int(rows/max_image*new_max), int(cols/max_image*new_max)))\n",
    "        new_image_path = os.path.join(outputimagepath,out_folder[int(train_test)])\n",
    "        cv2.imwrite(os.path.join(new_image_path, new_image_name),resized_I)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
